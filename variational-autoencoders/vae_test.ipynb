{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from variational_autoencoder import VAE\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from skimage import io, transform\n",
    "import os\n",
    "import sys\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_in_sub_dirs(path):\n",
    "    file_names = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            file_names.append(os.path.join(root, file))\n",
    "            \n",
    "    return file_names\n",
    "\n",
    "def get_data(path):\n",
    "    files_names = get_files_in_sub_dirs(path)\n",
    "    files_names = [file for file in files_names if file.endswith('.jpg')]\n",
    "    return files_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_loss(x, x_hat):\n",
    "    return F.mse_loss(x_hat, x, reduction='sum')\n",
    "\n",
    "def kl_divergence_loss(mu, stddev, beta=0.5):\n",
    "    return beta * torch.sum(torch.exp(stddev) + mu**2 - 1.0 - stddev)\n",
    "\n",
    "def loss_function(x, x_hat, mu, stddev, beta=0.5):\n",
    "    return reconstruction_loss(x, x_hat) + kl_divergence_loss(mu, stddev, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpsonImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None) -> None:\n",
    "        self.root_dir = root_dir\n",
    "        self.image_names = get_data(self.root_dir)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "    \n",
    "    def __getitem__(self, index) -> Any:\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, optimizer, train_dataloader, epochs, loss_output_interval):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    for step in tqdm(range(epochs), desc=\"Epoch\"):\n",
    "        running_loss = 0\n",
    "        total_running_loss = 0\n",
    "        \n",
    "        for i, (X, y) in enumerate(tqdm(train_dataloader, desc=\"Batch\", leave=False)):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            X_hat, mu, stddev = model(X)\n",
    "            loss = loss_function(X, X_hat, mu, stddev)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            total_running_loss += loss.item()\n",
    "        \n",
    "        if (step+1) % loss_output_interval == 0:\n",
    "            print(f' Epoch {step+1} Average Batch Loss: {total_running_loss/len(train_dataloader)}')\n",
    "            \n",
    "    model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
